{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OASIS Brain Stylegan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Import Complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# tf_device='/gpu:0'import time\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import random, randint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as k\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Import Complete\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up constant variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30\n",
    "IMAGE_SIZE = 28\n",
    "h, w = IMAGE_SIZE, IMAGE_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "outputs": [],
   "source": [
    "train_ds, ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "train_ds = train_ds['train']\n",
    "train_ds = train_ds.map(lambda x, y: layers.experimental.preprocessing.Rescaling(scale=1./127.5, offset=-1)(x))\n",
    "train_ds = train_ds.shuffle(BATCH_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE).cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess Images\n",
    "### Normalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preview Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (28, 28, 1)\n",
      "Data Type: <dtype: 'float32'>\n",
      "Min tf.Tensor(-1.0, shape=(), dtype=float32)\n",
      "Max tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "imageNum = randint(0, BATCH_SIZE-1)\n",
    "previewImage = list(train_ds.take(1))[0][imageNum]\n",
    "plt.imshow(previewImage, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Shape:\", previewImage.shape)\n",
    "print(\"Data Type:\", previewImage.dtype)\n",
    "print(\"Min\", tf.math.reduce_min(previewImage))\n",
    "print(\"Max\", tf.math.reduce_max(previewImage))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_152\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_203 (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_202 (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_201 (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1107 (Dense)              (None, 1568)         158368      input_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_151 (Functional)          (None, 100)          80800       input_201[0][0]                  \n",
      "                                                                 input_202[0][0]                  \n",
      "                                                                 input_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_125 (Reshape)           (None, 7, 7, 32)     0           dense_1107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1108 (Dense)              (None, 32)           3232        model_151[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 7, 7, 32)     9248        reshape_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_225 (TFOpLam (2,)                 0           dense_1108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_393 (TFOpLa ()                   0           conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_std_131 (TFOpLam ()                   0           conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1109 (Dense)              (None, 32)           3232        model_151[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_225 (S ()                   0           tf.compat.v1.shape_225[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_258 (TFOpLambd (None, 7, 7, 32)     0           conv2d_483[0][0]                 \n",
      "                                                                 tf.math.reduce_mean_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_114 (TFOpL ()                   0           tf.math.reduce_std_131[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_226 (TFOpLam (2,)                 0           dense_1109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_225 (TFOpLambda)     (None, 1, 1, None)   0           dense_1108[0][0]                 \n",
      "                                                                 tf.__operators__.getitem_225[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_126 (TFOpLambda (None, 7, 7, 32)     0           tf.math.subtract_258[0][0]       \n",
      "                                                                 tf.__operators__.add_114[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_226 (S ()                   0           tf.compat.v1.shape_226[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_126 (TFOpLambd (None, 7, 7, 32)     0           tf.reshape_225[0][0]             \n",
      "                                                                 tf.math.truediv_126[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_226 (TFOpLambda)     (None, 1, 1, None)   0           dense_1109[0][0]                 \n",
      "                                                                 tf.__operators__.getitem_226[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_120 (TFOpLambda)    (None, 7, 7, 32)     0           tf.math.multiply_126[0][0]       \n",
      "                                                                 tf.reshape_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_248 (UpSampling2D (None, 14, 14, 32)   0           tf.math.add_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1110 (Dense)              (None, 32)           3232        model_151[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 14, 14, 32)   9248        up_sampling2d_248[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_227 (TFOpLam (2,)                 0           dense_1110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_396 (TFOpLa ()                   0           conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_std_132 (TFOpLam ()                   0           conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1111 (Dense)              (None, 32)           3232        model_151[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_227 (S ()                   0           tf.compat.v1.shape_227[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_260 (TFOpLambd (None, 14, 14, 32)   0           conv2d_484[0][0]                 \n",
      "                                                                 tf.math.reduce_mean_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_115 (TFOpL ()                   0           tf.math.reduce_std_132[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_228 (TFOpLam (2,)                 0           dense_1111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_227 (TFOpLambda)     (None, 1, 1, None)   0           dense_1110[0][0]                 \n",
      "                                                                 tf.__operators__.getitem_227[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_127 (TFOpLambda (None, 14, 14, 32)   0           tf.math.subtract_260[0][0]       \n",
      "                                                                 tf.__operators__.add_115[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_228 (S ()                   0           tf.compat.v1.shape_228[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_127 (TFOpLambd (None, 14, 14, 32)   0           tf.reshape_227[0][0]             \n",
      "                                                                 tf.math.truediv_127[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_228 (TFOpLambda)     (None, 1, 1, None)   0           dense_1111[0][0]                 \n",
      "                                                                 tf.__operators__.getitem_228[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_121 (TFOpLambda)    (None, 14, 14, 32)   0           tf.math.multiply_127[0][0]       \n",
      "                                                                 tf.reshape_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_249 (UpSampling2D (None, 28, 28, 32)   0           tf.math.add_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1112 (Dense)              (None, 32)           3232        model_151[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 28, 28, 32)   9248        up_sampling2d_249[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_229 (TFOpLam (2,)                 0           dense_1112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_399 (TFOpLa ()                   0           conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_std_133 (TFOpLam ()                   0           conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1113 (Dense)              (None, 32)           3232        model_151[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_229 (S ()                   0           tf.compat.v1.shape_229[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_262 (TFOpLambd (None, 28, 28, 32)   0           conv2d_485[0][0]                 \n",
      "                                                                 tf.math.reduce_mean_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_116 (TFOpL ()                   0           tf.math.reduce_std_133[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_230 (TFOpLam (2,)                 0           dense_1113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_229 (TFOpLambda)     (None, 1, 1, None)   0           dense_1112[0][0]                 \n",
      "                                                                 tf.__operators__.getitem_229[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_128 (TFOpLambda (None, 28, 28, 32)   0           tf.math.subtract_262[0][0]       \n",
      "                                                                 tf.__operators__.add_116[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_230 (S ()                   0           tf.compat.v1.shape_230[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_128 (TFOpLambd (None, 28, 28, 32)   0           tf.reshape_229[0][0]             \n",
      "                                                                 tf.math.truediv_128[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_230 (TFOpLambda)     (None, 1, 1, None)   0           dense_1113[0][0]                 \n",
      "                                                                 tf.__operators__.getitem_230[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_122 (TFOpLambda)    (None, 28, 28, 32)   0           tf.math.multiply_128[0][0]       \n",
      "                                                                 tf.reshape_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1114 (Dense)              (None, 28, 28, 1)    33          tf.math.add_122[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 286,337\n",
      "Trainable params: 286,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LATENT_SIZE = 100\n",
    "\n",
    "def make_generator_model():\n",
    "    latent_input0 = layers.Input(shape=(LATENT_SIZE,))\n",
    "    # latent_input1 = layers.Input(shape=(LATENT_SIZE,))\n",
    "    # latent_input2 = layers.Input(shape=(LATENT_SIZE,))\n",
    "\n",
    "    # Mapping Network\n",
    "    mnfc_input = layers.Input(shape=(LATENT_SIZE,))\n",
    "    mnfc = layers.Dense(LATENT_SIZE, activation=\"relu\")(mnfc_input)\n",
    "    for i in range(7):\n",
    "        mnfc = layers.Dense(LATENT_SIZE, activation=\"relu\")(mnfc)\n",
    "    mapping_network = tf.keras.Model(inputs=[mnfc_input], outputs=[mnfc])\n",
    "\n",
    "    # w0 = mapping_network(latent_input0)\n",
    "    # w1 = mapping_network(latent_input1)\n",
    "    # w2 = mapping_network(latent_input2)\n",
    "\n",
    "    # Noises\n",
    "    # noise_input0 = layers.Input(shape=(7, 7, 1))\n",
    "    # n0 = layers.Dense(32, activation=\"relu\")(noise_input0)\n",
    "    # noise_input1 = layers.Input(shape=(14, 14, 1))\n",
    "    # n1 = layers.Dense(32, activation=\"relu\")(noise_input1)\n",
    "    # noise_input2 = layers.Input(shape=(28, 28, 1))\n",
    "    # n2 = layers.Dense(32, activation=\"relu\")(noise_input2)\n",
    "\n",
    "    # synthesis Network\n",
    "    # 7x7\n",
    "    l1_1 = layers.Dense(7*7*32, activation=\"relu\")(latent_input0)\n",
    "    l1_2 = layers.Reshape((7, 7, 32))(l1_1)\n",
    "    # l1_3 = layers.Add()([l1_2, n0])\n",
    "    # AdaIN\n",
    "    def AdaIN(x, y):\n",
    "        x_mean, x_std = k.mean(x), k.std(x)\n",
    "        y_mean, y_std = k.mean(y), k.std(y)\n",
    "        return tf.multiply(y_std, tf.divide(x - x_mean, x_std)) + y_mean\n",
    "    # l1_4 = AdaIN(l1_3, w0)\n",
    "    l1_5 = layers.Conv2D(32, (3, 3), padding=\"same\")(l1_2)\n",
    "    # l1_6 = layers.Add()([l1_5, n0])\n",
    "    # l1_7 = AdaIN(l1_6, w0)\n",
    "\n",
    "    # 14x14\n",
    "    l2_1 = layers.UpSampling2D()(l1_5)\n",
    "    l2_2 = layers.Conv2D(32, (3, 3), padding=\"same\")(l2_1)\n",
    "    # l2_3 = layers.Add()([l2_2, n1])\n",
    "    # l2_4 = AdaIN(l2_3, w1)\n",
    "    l2_5 = layers.Conv2D(32, (3, 3), padding=\"same\")(l2_2)\n",
    "    # l2_6 = layers.Add()([l2_5, n1])\n",
    "    # l2_7 = AdaIN(l2_6, w1)\n",
    "\n",
    "    # 28x28\n",
    "    l3_1 = layers.UpSampling2D()(l2_5)\n",
    "    l3_2 = layers.Conv2D(32, (3, 3), padding=\"same\")(l3_1)\n",
    "    # l3_3 = layers.Add()([l3_2, n2])\n",
    "    # l3_4 = AdaIN(l3_3, w2)\n",
    "    l3_5 = layers.Conv2D(32, (3, 3), padding=\"same\")(l3_2)\n",
    "    # l3_6 = layers.Add()([l3_5, n2])\n",
    "    # l3_7 = AdaIN(l3_6, w2)\n",
    "\n",
    "    l6 = layers.Dense(1)(l3_2)\n",
    "    output_layer = layers.Activation(activation=\"tanh\")(l6)\n",
    "    model = tf.keras.Model(inputs=[latent_input0],\n",
    "                           outputs=[output_layer])\n",
    "    return model\n",
    "\n",
    "def make_generator_model():\n",
    "    # AdaIN\n",
    "    def AdaIN(x, ys, yb):\n",
    "        x_mean, x_std = k.mean(x), k.std(x)\n",
    "        ys = tf.reshape(ys, (-1, 1, 1, tf.shape(ys)[-1]))\n",
    "        yb = tf.reshape(yb, (-1, 1, 1, tf.shape(yb)[-1]))\n",
    "        return tf.add(tf.multiply(ys, tf.divide(x - x_mean, x_std+1e-7)), yb)\n",
    "\n",
    "    input_layer0 = layers.Input((LATENT_SIZE,))\n",
    "    input_layer1 = layers.Input((LATENT_SIZE,))\n",
    "    input_layer2 = layers.Input((LATENT_SIZE,))\n",
    "\n",
    "    # Mapping Network\n",
    "    mnfc_input = layers.Input(shape=(LATENT_SIZE,))\n",
    "    mnfc = layers.Dense(LATENT_SIZE, activation=\"relu\")(mnfc_input)\n",
    "    for i in range(7):\n",
    "        mnfc = layers.Dense(LATENT_SIZE, activation=\"relu\")(mnfc)\n",
    "    mapping_network = tf.keras.Model(inputs=[mnfc_input], outputs=[mnfc])\n",
    "\n",
    "    w0 = mapping_network(input_layer0)\n",
    "    w1 = mapping_network(input_layer1)\n",
    "    w2 = mapping_network(input_layer2)\n",
    "\n",
    "    # Synthesis Network\n",
    "    # 7x7\n",
    "    x = layers.Dense(7*7*32)(input_layer2)\n",
    "    x = layers.Reshape((7, 7, 32))(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    scale_dense = layers.Dense(32)(w0)\n",
    "    bias_dense = layers.Dense(32)(w0)\n",
    "    x = AdaIN(x, scale_dense, bias_dense)\n",
    "\n",
    "    # 14x14\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    scale_dense = layers.Dense(32)(w1)\n",
    "    bias_dense = layers.Dense(32)(w1)\n",
    "    x = AdaIN(x, scale_dense, bias_dense)\n",
    "\n",
    "    # 28x28\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    scale_dense = layers.Dense(32)(w2)\n",
    "    bias_dense = layers.Dense(32)(w2)\n",
    "    x = AdaIN(x, scale_dense, bias_dense)\n",
    "\n",
    "    x = layers.Dense(1, activation=\"tanh\")(x)\n",
    "    model = tf.keras.Model(inputs=[input_layer0, input_layer1, input_layer2],\n",
    "                           outputs=[x])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_generator_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# synthesis Network\n",
    "# 7x7\n",
    "x = layers.Dense(7*7*LATENT_SIZE, activation=\"relu\")(tf.random.normal((1, LATENT_SIZE)))\n",
    "x = layers.Reshape((7, 7, LATENT_SIZE))(x)\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=tf.keras.initializers.GlorotNormal())(x)\n",
    "\n",
    "# 14x14\n",
    "x = layers.UpSampling2D()(x)\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=tf.keras.initializers.GlorotNormal())(x)\n",
    "\n",
    "# 28x28\n",
    "x = layers.UpSampling2D()(x)\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=tf.keras.initializers.GlorotNormal())(x)\n",
    "\n",
    "x = layers.Dense(1, activation=\"tanh\")(x)\n",
    "plt.imshow(x[0], cmap=\"gray\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.49750742]], dtype=float32)>"
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator(np.reshape(x[0], (1, 28, 28, 1)), training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    realLoss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fakeLoss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return realLoss + fakeLoss\n",
    "\n",
    "def generator_loss(fakeOutput):\n",
    "    return cross_entropy(tf.ones_like(fakeOutput), fakeOutput)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Optimizers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "outputs": [],
   "source": [
    "generatorOptimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminatorOptimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "outputs": [],
   "source": [
    "NUM_SAMPLES_TO_GENERATE = 8\n",
    "NUM_CHECKPOINT = 10\n",
    "\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = [tf.random.normal([NUM_SAMPLES_TO_GENERATE, LATENT_SIZE]) for i in range(3)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./checkpoints2\"\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    generator_optimizer=generatorOptimizer,\n",
    "    discriminator_optimizer=discriminatorOptimizer,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Training Steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    latent = [tf.random.normal((BATCH_SIZE, LATENT_SIZE)) for i in range(3)]\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(latent, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        genLoss = generator_loss(fake_output)\n",
    "        discLoss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(genLoss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(discLoss, discriminator.trainable_variables)\n",
    "\n",
    "    generatorOptimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminatorOptimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return genLoss, discLoss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input, history):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 4), constrained_layout=True)\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow((predictions[i].numpy()), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.savefig(\"./img2/image_at_epoch_{:04d}.png\".format(epoch))\n",
    "    plt.show()\n",
    "    plt.plot(history['gen_loss'])\n",
    "    plt.plot(history['disc_loss'])\n",
    "    plt.legend([\"Generator Loss\", \"Discriminator Loss\"])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    history = {\n",
    "        'gen_loss': [],\n",
    "        'disc_loss': []\n",
    "    }\n",
    "\n",
    "    generate_and_save_images(generator, 0, seed, history)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        gen_loss = []\n",
    "        disc_loss = []\n",
    "        for image_batch in tqdm(dataset):\n",
    "            h = train_step(image_batch)\n",
    "            gen_loss.append(h[0])\n",
    "            disc_loss.append(h[1])\n",
    "        history['gen_loss'].append(tf.math.reduce_mean(gen_loss))\n",
    "        history['disc_loss'].append(tf.math.reduce_mean(disc_loss))\n",
    "        print(f\"EPOCH: {epoch}\\ngen_loss: {history['gen_loss'][-1]}\\ndisc_loss: {history['disc_loss'][-1]}\")\n",
    "        # Produce images for the GIF as you go\n",
    "        clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed, history)\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % NUM_CHECKPOINT == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print(\"Time for epoch {} is {} sec\".format(epoch + 1, time.time() - start))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed, history)\n",
    "    return history\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x288 with 64 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/235 [00:00<00:08, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 15.54800009727478 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 73/235 [00:02<00:06, 24.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-757-ab454faf9439>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Starting\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_ds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Finished\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-756-aaa4ecb3def0>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(dataset, epochs)\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mgen_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[0mdisc_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mimage_batch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m             \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m             \u001B[0mgen_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python39\\lib\\site-packages\\tqdm\\std.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1166\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1167\u001B[1;33m             \u001B[1;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1168\u001B[0m                 \u001B[1;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1169\u001B[0m                 \u001B[1;31m# Update and possibly print the progressbar.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    759\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    760\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 761\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_internal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    762\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOutOfRangeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    763\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001B[0m in \u001B[0;36m_next_internal\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    741\u001B[0m     \u001B[1;31m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    742\u001B[0m     \u001B[1;31m# to communicate that there is no more data to iterate over.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 743\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecution_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSYNC\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    744\u001B[0m       ret = gen_dataset_ops.iterator_get_next(\n\u001B[0;32m    745\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator_resource\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python39\\lib\\contextlib.py\u001B[0m in \u001B[0;36m__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    115\u001B[0m         \u001B[1;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"generator didn't yield\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001B[0m in \u001B[0;36mexecution_mode\u001B[1;34m(mode)\u001B[0m\n\u001B[0;32m   2188\u001B[0m     \u001B[0mexecutor_old\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecutor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2189\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2190\u001B[1;33m       \u001B[0mexecutor_old\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2191\u001B[0m       \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecutor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexecutor_new\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2192\u001B[0m       \u001B[1;32myield\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\executor.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     67\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[1;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m     \u001B[0mpywrap_tfe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTFE_ExecutorWaitForAllPendingNodes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mclear_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting\")\n",
    "history = train(train_ds, EPOCHS)\n",
    "print(\"Finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}