{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8762308",
   "metadata": {},
   "source": [
    "# OASIS Brain Stylegan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37140cc0",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab17d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Import Complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# tf_device='/gpu:0'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import random, randint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as k\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "print(\"Import Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up constant variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "IMAGE_SIZE = (64, 64)\n",
    "h, w = IMAGE_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbaa4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9664 files belonging to 1 classes.\n",
      "Found 544 files belonging to 1 classes.\n",
      "Found 1120 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.getcwd()+'\\\\keras_png_slices_data\\\\keras_png_slices_train',\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(h, w),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.getcwd()+'\\\\keras_png_slices_data\\\\keras_png_slices_test',\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(h, w),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validate_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.getcwd()+'\\\\keras_png_slices_data\\\\keras_png_slices_validate',\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(h, w),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess Images\n",
    "### Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.cast(image/255., tf.float32)\n",
    "    return image\n",
    "\n",
    "train_ds = train_ds.map(preprocess_image).prefetch(buffer_size=tf.data.experimental.AUTOTUNE).cache()\n",
    "test_ds = test_ds.map(preprocess_image).prefetch(buffer_size=tf.data.experimental.AUTOTUNE).cache()\n",
    "validate_ds = validate_ds.map(preprocess_image).prefetch(buffer_size=tf.data.experimental.AUTOTUNE).cache()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preview Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (64, 64, 1)\n",
      "Data Type: <dtype: 'float32'>\n",
      "Min tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Max tf.Tensor(0.9107843, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "imageNum = randint(0, 127)\n",
    "previewImage = list(train_ds.take(1))[0][imageNum]\n",
    "plt.imshow(previewImage, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Shape:\", previewImage.shape)\n",
    "print(\"Data Type:\", previewImage.dtype)\n",
    "print(\"Min\", tf.math.reduce_min(previewImage))\n",
    "print(\"Max\", tf.math.reduce_max(previewImage))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 512)          51712       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 512)          262656      dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 512)          262656      dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 512)          262656      dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 8192)         827392      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 4, 4, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 512)          262656      dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 4, 4, 512)    0           dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 4, 4, 512)    1024        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 512)          262656      dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 512)    0           reshape_8[0][0]                  \n",
      "                                                                 dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 512)          262656      dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_48 (TFOpLam ()                   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 512)          262656      dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_26 (TFOpLambda (None, 4, 4, 512)    0           add_8[0][0]                      \n",
      "                                                                 tf.math.reduce_mean_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_std_16 (TFOpLamb ()                   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_std_17 (TFOpLamb ()                   0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_8 (TFOpLambda)  (None, 4, 4, 512)    0           tf.math.subtract_26[0][0]        \n",
      "                                                                 tf.math.reduce_std_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_8 (TFOpLambda) (None, 4, 4, 512)    0           tf.math.reduce_std_17[0][0]      \n",
      "                                                                 tf.math.truediv_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_51 (TFOpLam ()                   0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 4, 4, 512)    0           tf.math.multiply_8[0][0]         \n",
      "                                                                 tf.math.reduce_mean_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 1, 512)    2359808     tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 512)    0           conv2d_4[0][0]                   \n",
      "                                                                 dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_54 (TFOpLam ()                   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_29 (TFOpLambda (None, 4, 4, 512)    0           add_9[0][0]                      \n",
      "                                                                 tf.math.reduce_mean_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_std_18 (TFOpLamb ()                   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_std_19 (TFOpLamb ()                   0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_9 (TFOpLambda)  (None, 4, 4, 512)    0           tf.math.subtract_29[0][0]        \n",
      "                                                                 tf.math.reduce_std_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_9 (TFOpLambda) (None, 4, 4, 512)    0           tf.math.reduce_std_19[0][0]      \n",
      "                                                                 tf.math.truediv_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_57 (TFOpLam ()                   0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 4, 4, 512)    0           tf.math.multiply_9[0][0]         \n",
      "                                                                 tf.math.reduce_mean_57[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 5,078,528\n",
      "Trainable params: 5,078,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_generator_model():\n",
    "    latent_input0 = layers.Input(shape=(100,))\n",
    "\n",
    "    # Mapping Network\n",
    "    mnfc = layers.Dense(512, activation=\"relu\")(latent_input0)\n",
    "    for i in range(7):\n",
    "        mnfc = layers.Dense(512, activation=\"relu\")(mnfc)\n",
    "\n",
    "    # Noises\n",
    "    noise_input0 = layers.Input(shape=(4, 4, 1))\n",
    "    n1 = layers.Dense(512, activation=\"relu\")(noise_input0)\n",
    "\n",
    "    # synthesis Network\n",
    "    l1_1 = layers.Dense(4*4*512, activation=\"relu\")(latent_input0)\n",
    "    l1_2 = layers.Reshape((4, 4, 512))(l1_1)\n",
    "    l1_3 = layers.Add()([l1_2, n1])\n",
    "    # AdaIN\n",
    "    def AdaIN(x, y):\n",
    "        x_mean, x_std = k.mean(x), k.std(x)\n",
    "        y_mean, y_std = k.mean(y), k.std(y)\n",
    "        return tf.multiply(y_std, tf.divide(x - x_mean, x_std)) + y_mean\n",
    "    l1_4 = AdaIN(l1_3, mnfc)\n",
    "    l1_5 = layers.Conv2D(512, (3, 3), (2, 2))(l1_4)\n",
    "    l1_6 = layers.Add()([l1_5, n1])\n",
    "    l1_7 = AdaIN(l1_6, mnfc)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[latent_input0, noise_input0], outputs=[l1_7])\n",
    "    return model\n",
    "\n",
    "model = make_generator_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(IMAGE_SIZE, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(IMAGE_SIZE * 2, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(IMAGE_SIZE * 4, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(IMAGE_SIZE * 8, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    realLoss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fakeLoss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return realLoss + fakeLoss\n",
    "\n",
    "def generator_loss(fakeOutput):\n",
    "    return cross_entropy(tf.ones_like(fakeOutput), fakeOutput)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Optimizers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "generatorOptimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminatorOptimizer = tf.keras.optimizers.Adam(1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Training Steps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_step(images):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 4), constrained_layout=True)\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow((predictions[i].numpy() * 127.5 + 127.5).astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.savefig(\"./betterimg/image_at_epoch_{:04d}.png\".format(epoch))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(train, test, validate, epochs):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}