{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Import Complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# tf_device='/gpu:0'import time\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import random, randint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as k\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Import Complete\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def get_mnist_dataset():\n",
    "        \"\"\"Retrieve MNIST Digits dataset from tfds. Normalise, shuffle and batch the dataset.\"\"\"\n",
    "        dataloader = tfds.load('mnist', as_supervised=True)\n",
    "        dataset = dataloader['train']\n",
    "        # Cast [0,255] images to [-1,1].\n",
    "        dataset = dataset.map(lambda image, label: layers.experimental.preprocessing.Rescaling(scale=1. / 127.5, offset=-1)(image))\n",
    "        dataset = dataset.shuffle(BATCH_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        print('MNIST Digits dataset loaded.')\n",
    "        return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess Images\n",
    "### Normalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Digits dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "train_ds = get_mnist_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1568)              158368    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 28, 28, 1)         33        \n",
      "=================================================================\n",
      "Total params: 186,145\n",
      "Trainable params: 186,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "generator = tf.keras.models.Sequential()\n",
    "generator.add(layers.Input((100,)))\n",
    "generator.add(layers.Dense(7*7*32))\n",
    "generator.add(layers.Reshape((7, 7, 32)))\n",
    "generator.add(layers.Conv2D(32, (3, 3), padding=\"same\"))\n",
    "generator.add(layers.UpSampling2D())\n",
    "generator.add(layers.Conv2D(32, (3, 3), padding=\"same\"))\n",
    "generator.add(layers.UpSampling2D())\n",
    "generator.add(layers.Conv2D(32, (3, 3), padding=\"same\"))\n",
    "generator.add(layers.Dense(1, activation=\"tanh\"))\n",
    "\n",
    "print(generator.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 1569      \n",
      "=================================================================\n",
      "Total params: 11,137\n",
      "Trainable params: 11,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 28\n",
    "\n",
    "discriminator = tf.keras.models.Sequential()\n",
    "\n",
    "discriminator.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 1]))\n",
    "discriminator.add(layers.LeakyReLU())\n",
    "discriminator.add(layers.Dropout(0.2))\n",
    "\n",
    "discriminator.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same'))\n",
    "discriminator.add(layers.LeakyReLU())\n",
    "discriminator.add(layers.Dropout(0.2))\n",
    "\n",
    "# discriminator.add(layers.Conv2D(IMAGE_SIZE * 4, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 1]))\n",
    "# discriminator.add(layers.LeakyReLU())\n",
    "# discriminator.add(layers.Dropout(0.2))\n",
    "#\n",
    "# discriminator.add(layers.Conv2D(IMAGE_SIZE * 8, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 1]))\n",
    "# discriminator.add(layers.LeakyReLU())\n",
    "# discriminator.add(layers.Dropout(0.2))\n",
    "\n",
    "discriminator.add(layers.Flatten())\n",
    "discriminator.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "print(discriminator.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    realLoss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fakeLoss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return realLoss + fakeLoss\n",
    "\n",
    "def generator_loss(fakeOutput):\n",
    "    return cross_entropy(tf.ones_like(fakeOutput), fakeOutput)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "generatorOptimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminatorOptimizer = tf.keras.optimizers.Adam(1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    latent = tf.random.normal((BATCH_SIZE, 100))\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(latent, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        genLoss = generator_loss(fake_output)\n",
    "        discLoss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(genLoss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(discLoss, discriminator.trainable_variables)\n",
    "\n",
    "    generatorOptimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminatorOptimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return genLoss, discLoss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "NUM_SAMPLES_TO_GENERATE = 8\n",
    "seed = tf.random.normal([NUM_SAMPLES_TO_GENERATE, 100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 4), constrained_layout=True)\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow((predictions[i].numpy()), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    history = {\n",
    "        'gen_loss': [],\n",
    "        'disc_loss': []\n",
    "    }\n",
    "\n",
    "    generate_and_save_images(generator, 0, seed)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        gen_loss = []\n",
    "        disc_loss = []\n",
    "        for image_batch in tqdm(dataset):\n",
    "            h = train_step(image_batch)\n",
    "            gen_loss.append(h[0])\n",
    "            disc_loss.append(h[1])\n",
    "        history['gen_loss'].append(sum(gen_loss))\n",
    "        history['disc_loss'].append(sum(disc_loss))\n",
    "        print(f\"EPOCH: {epoch}\\ngen_loss: {sum(gen_loss)}\\ndisc_loss: {sum(disc_loss)}\")\n",
    "\n",
    "        # Produce images for the GIF as you go\n",
    "        clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "        print(\"Time for epoch {} is {} sec\".format(epoch + 1, time.time() - start))\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x288 with 8 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAEnCAYAAABSVLy9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkf0lEQVR4nO3daZBU5dnG8dPCDAPIsMyAIwjIIgYFURPUWIIxamkMRFASS01ccCUpt7iUlaLKGIxREtTEVCruEdS4opFgNGJKFpXgEkSIDiCiiCDIsDMzzPZ+eCt533PfFz2ne3o53fP/fTtXzkwfep4586S9+u5ES0tLAAAAgP+zX74vAAAAIG7YIAEAABhskAAAAAw2SAAAAAYbJAAAAIMNEgAAgNEx2f+YSCSYAYB9amlpSbR2TjGsoUQi/M/s0KGDO2e//fz/11AjNBobGyOd1160lzWEzLC/i0EQBM3NzUnXEOsH/6Hu3Y2NjftcP7yCBAAAYLBBAgAAMNggAQAAGEk7SAB8R0j1iFQ3oj13i4Bs4HcKbdHU1JTS+byCBAAAYLBBAgAAMNggAQAAGGyQAAAAjIItaavBfEpzc3PGHlMVcaMODbTlsFTLYsgf9XO32lIepeANAPHDK0gAAAAGGyQAAACDDRIAAIDBBgkAAMAo2JL2IYcc4jJVfF6/fn3ouK6uzp2jCrGqONurVy+XDR061GW7d+92mbVixYpI14HsUQX7Aw44wGUjRowIHe/du9edc/jhh7ts06ZNLuvY0f/KVVVVueyBBx5wmV3ftbW17hwUBor5QPzxChIAAIDBBgkAAMBggwQAAGAkkv1370QikfP/KK6GLE6ePNllf/jDH1ym/rt+1IGSVtQBkzt27HDZn/70J5c988wzoePFixendV1x0tLS0uoExXysIdUt6tGjh8tWrVoV6bwogyIzbePGjS6bN29e6Pjqq69252zbts1lce62xHUNRaXWWmVlpctmzpwZOh40aJA7R93n1qxZ47KysjKXNTQ0uEx1Mr/44guXFbrW1lCc10+hKS8vDx1PmTLFnTN37lyXLV++PGvX1FbJ1g+vIAEAABhskAAAAAw2SAAAAAYbJAAAACN2Je3Bgwe7bPbs2S4bNWpULi4nRBW3Venxkksucdk//vGP0HFjY2PmLixP4lqwnTp1qsvOOeccl9kBkPmihpdeddVVLnvxxRdDx9u3b3fn1NfXZ+7CciCua6hz584uswXVIAiCJUuWuKxPnz4uKy0tDR2r4r9644YqgQ8fPtxl6vupgbUTJkxo9TELDSXt7FD3oFtvvTV03L17d3dOTU2Ny4YNG+ayrVu3tuHqMoeSNgAAQArYIAEAABhskAAAAAw2SAAAAEbsStoVFRUumzhxosvuv/9+l2Vy4rF6Xq699lqXPfXUUy7bvHmzy6JO5o4r9dw2NzfnvWDbtWtXl+3cuVNdRzYvIzI12T3Ok66zLdcl7S5durjsySefdNn48eMz9ZCRqTduqJJ2W9bynj17Qsd2OnsQBMGiRYtcpqYjqynf6g0H2VZsJe2qqiqXRZmArianK6pErT5BwL6xoC1WrlzpMvVmmueeey7S97P3zLbcQylpAwAApIANEgAAgMEGCQAAwGCDBAAAYMSupK2oYquaEltWVpaxx1RF6yOPPNJlqhCsCtnqeguJ+hk0NTXltGCryqnf/OY3XaZKptkuaaufuZ1aHARBMGfOnKxeR6HJdkm7pKQkdKzWxujRo9VjpvuQaYtaNFVrTU1V38fvbOhYvclBff+PPvrIZTfddJPLXnvtNZdlWy5L2lHXhSrXf+tb33LZpEmTXHb55Zen/bhRqHWW7fWuiuEPPvigy26++eZI3y+Tb2yhpA0AAJACNkgAAAAGGyQAAACDDRIAAIBRECVtVSBTU2dVKTGKkSNHumz16tUu27t3r8tOOOEElz3++OMu+/rXvx463rRpUyqXGEu5noKs1oGaALthwwaX2bJuEKS/Xurr613WuXNnl2V7QvbgwYNd1q1bN5ctW7bMZXGZ3h1lDe23337uYtWU36FDh7rsyiuvDB3/5Cc/cefEZcr6rl27XPbhhx+6TE35Vm8qUb8bM2bMCB1feOGF7px9TM132YIFC1x20kknuSzbMlXSVsVqO3n9Bz/4gTtHPfdnnHGGyy666CKXderUKcqlZZSdph4E+vepY8eOaX1/NdH7V7/6lcvuvPNOl6nfgWyjpA0AAJACNkgAAAAGGyQAAACDDRIAAICRXgsrx9It00a1//77R3pMldnydRAEQXl5uctOPPHE0PEzzzyTyiUi0OVRVZieP3++ywYNGuSyPn36uEwVNW0BWz1mLtjC6OzZs905N9xwg8viUsjOJFUEVdN6586dGzq+5JJL3DmqYJ8PH3/8sctUuVW9wSPqz7iysjJ0HLWgrp7vurq6SF9bKNT9/cADDwwdX3HFFe4c9YahhoaGSJkqR6f7pgFVpF+6dKnLxo4d67KJEye67N5773WZXWfqjUtXXXWVy9S9Sq2puOEVJAAAAIMNEgAAgMEGCQAAwGCDBAAAYMSupK0Kk+edd57LMlncVoXpr776ymWXXnqpy8aMGeMyVT774osv0rw6/IcqIaqi6Nlnn+0yW3AOAr3Wzj33XJfdfvvtoWNV6j/mmGNcpn7mKlPTeZ944gmXWaqsq6YbFzpVQFbFWDVB3Wa2pBwEQXD00Ue77LLLLnPZuHHjXKYml6sSv11/qojbu3dvl61Zs8Zl6mvV/fCXv/yly77zne+4LIq33nrLZVOmTEnrexUS+7z26tXLnaPelDNz5kyXqd9XtR7nzZvnshdeeCF0vGLFCndOWzz22GMuU/cg+3yo38NiwitIAAAABhskAAAAgw0SAACAEbsO0umnn+6y6dOnZ/UxKyoqIp23bds2l91xxx0uU9f79ttvp3xdaJ3qJalPq1YDzdQnaau1YDsfqgOyaNGipNeZ7DpUPyqKo446KtL3x/9Ra0P97N555x2XqQ7SNddc47L+/fu7rGvXrq1eW0lJictUP2rjxo0umzBhgsvUUEzbIVG/P9XV1S479dRTXVZsa009F/bT5Tdv3uzO2bJli8vuv/9+l1VVVblM/U1Rz38+htOq50NlxYxXkAAAAAw2SAAAAAYbJAAAAIMNEgAAgJFI9inQHTp0cP9jtktaV155pctuu+02l0UtVkehhl19+umnLlOFSVX6VIMii/ET1VtaWlr92OlEIhGLf7gqVqshbe+9957LDjrooKxcU6rsulKfBF5oJcpCWkOKKl+rkvb7778fOu7Y0b8/xhaCg0APFlXl6MMOO8xl6jHsve7GG2905/z2t791WZzvX62toajrR90j7O/Y97//fXeOGjg7a9Ysl6kSftS/H8ieZOuHV5AAAAAMNkgAAAAGGyQAAACDDRIAAICRdJJ2Pgqfs2fPdpkqbqtPVVYlO0uVDdW/U306dt++fV3W0NDgsnXr1rV6XpxLj8VIPd/qZ6em4salpG0/DZw1lH/qnqM+3d1SbwxZv369y+69916XHX/88S772te+5jK1vnfv3h06fvzxx9057XVdqX+3LcSrv09qDXTo0MFlw4YNc9natWtdtn37dpep9ZKuKH8ng6D9roP/j1eQAAAADDZIAAAABhskAAAAgw0SAACAkbSknQ9bt2512X333eey6dOnR/p+dtJtXV2dO0eVGVUJ/Lnnnov0mBdccIHLli5dGjpmWmr+qbXwyiuvuGzUqFFZvQ71JoFFixa5bN68eaHjKJOSg4CyZaaoN26o0u7BBx/sMvtzefbZZ9051113ncvq6+tdtmTJEpepicyq9P3vf//bZZb6dxbahPZMsb876nlW1Bo4//zzXab+zpx99tkus9O6VdFa/dwU9bNU09mXLVvmsgsvvDB0/NFHH0V6zELFK0gAAAAGGyQAAACDDRIAAIDBBgkAAMCIXUlbFUpVMW7btm0us4XsIAiC2tra0LEqlalJyV26dHGZmoSqynIXXXSRy2655ZbQcU1NjTsHuaXKigMGDHCZLdRHnbyuzlPFcLWGqqurXWYnuR9wwAHunA0bNriMNwRkRmVlpctGjx7tMvXz3LFjR+j4448/dueo+5f6XmqNqnW1cOFClx155JGh47vuusudM23aNJetXLnSZdi3IUOGuOyoo46K9LW2kB0EejJ3utS9qqyszGVHHHGEyyZNmhQ6vu222zJ2XXHEK0gAAAAGGyQAAACDDRIAAIDBBgkAAMBIJJuym0gkYjGCV5XKysvLXdajRw+XVVRUhI63b9/uznnkkUdcduyxx7qspKQk2WX+1+eff+4yW+bcuHFjpO8VZy0tLb5BamRyDal1oEqsak2rwrT6WlWGLC0tDR1XVVW5c8466yyXjRgxwmXqzQVqvbzwwgsus0VK9YYDNUk7znK9htpCTS5fvHixywYPHuyyXbt2hY7nzJnjznniiSdc9q9//SvStalJyKqcP2jQoNCxKnLbaw0CXTCOOlU621pbQ9leP+qesWrVKpepqdnqXqX+jsWFXRt9+vRx59g3RsVdsvXDK0gAAAAGGyQAAACDDRIAAIDBBgkAAMCI3SRtRRVsVdlVZWvXrg0dq6KlLXIHQdsml6qJuwMHDgwdF0NJO9dUqVpNgFWTaO0k4yDQ60pltoy6Zs0ad86MGTNcluwNECg8qgCvJmmre4xdC6pAnYv1Yu+Hb775pjtH3Q/r6+uzdUkFT/2t+PLLL12myu+9e/fOyjVli32jTLFP6ecVJAAAAIMNEgAAgMEGCQAAwCiIQZGZpHosDQ0NLsvkpycHge8vqE/uVsPe4izXQ/7UcFA10PN73/uey1QnQA3r++CDD1ymeknIjEIaFFmMVIdP/U2Icwcp34MiVefs/PPPd9nkyZNdpobODh061GVqSG62qXXw9ttvh47V/bfQMCgSAAAgBWyQAAAADDZIAAAABhskAAAAoyAGRWaS/WT2IMh8IVuxRb4xY8a4c+bPn++yQvt09mxSRcV169a5TBWyDz/8cJepT51Wmf1kbgZAoljEuXxdKNSbON59912XnXLKKS7r0aOHy+J8f6mrq8v3JeQUryABAAAYbJAAAAAMNkgAAAAGGyQAAACj3ZW0jzrqqHxfQhAEQfDGG2+4jEJ2cjt37nSZes5efPFFl6ki/qRJk1x27bXXumzz5s2h4xUrVrhzfvOb37iMqdzIJ/WpAVHEuSQcR+p3Wr15ZOvWrS5Tnw6Q7s8tF6ZPn57vS8gpXkECAAAw2CABAAAYbJAAAAAMNkgAAABGIlkhL5FIFF1bT5V11TTZtkzX3rRpk8tOO+200PHSpUvT/v5x0dLS0mqbMJNrKGp5UU3cVtmoUaNc9sgjj7hs+PDhrT6mKmWq7zVt2jSXtedSbK7XEIpPa2soH+tH/f0YPXq0y04++WSXnXXWWS478sgjQ8fqXtjU1OQydV5DQ0Ok89TfxQEDBoSOt2/f7s4pNMnWD68gAQAAGGyQAAAADDZIAAAABhskAAAAo92VtKMaMmSIyx588EGXXXzxxS5bu3ZtNi4pdoqxYNu/f3+XLV++PHRcUlLizlHFRzVhd+rUqS576623XPbhhx+6rLa21mWFLq5raMSIES57/fXXXVZRUZGDqwnr3r27y3bs2JHz64iLOJa020IVpjt37hw6VgVqVdJO9/sHgb4Xrly5MnRcDG8woaQNAACQAjZIAAAABhskAAAAgw0SAACAQUl7Hzp16uQyNR11z549ubicWIprwTbTbKlRrQP1e1RaWuoyVa5UVMG7GMV1DalJ92ryej6oqfDFUJZNV7GVtBX7M2/L/UGVtHv27Omyvn37uqy6ujp0rN6cUmgoaQMAAKSADRIAAIDBBgkAAMBggwQAAGBQ0o4RVepVJbi4FDLjWrBF4cj1GlIF1bKyMpft3r070tdm24YNG1ymyrPtWXsoaWebKv6r9W6zxsbGrF1TrlDSBgAASAEbJAAAAIMNEgAAgNEx3xcQV2oYYNRPS073+6tuUVz6RkCxUj2K9evXu6xfv34uy2Qv6bXXXnPZKaeckrHvD+xL1L89qqtUzNrXvxYAACACNkgAAAAGGyQAAACDDRIAAIDBoMggCI499liXqeKm+oTvdIvbqtxZaIVsBkWirXK9hjp29O9LUW+YuOKKK1ymCtPf/e53XabuCfPnzw8dT5s2zZ2zYMECl6F1xTYoUv1tsOXo5uZmd45ax+q8qNTX2msrtL9Z6rltbm5mUCQAAEBUbJAAAAAMNkgAAAAGGyQAAACj3U3SVpNAV6xY4TJVeFOiTtK1ZbZMl9vSvY5Mf39gX/Ixhdeu29LSUnfOgAEDXFZfX++yN99802Xl5eUue/bZZ132t7/9LXS8YcMGf7HAPkQpW6tzMv3pDIVWyrZSvQfxChIAAIDBBgkAAMBggwQAAGCwQQIAADCSTtIGAABoj3gFCQAAwGCDBAAAYLBBAgAAMNggAQAAGGyQAAAADDZIAAAABhskAAAAgw0SAACAwQYJAADA6Jjsf0wkEu1izPZ++/l9YseO/qnp3bu3yyorK122bt06l+3cuTN03NTU5M5pbm5Oep1x09LSkmjtnHysIfXzVBPjmSKff3FdQ3GWSLT6lO3zvEK6x6jrV1lTU1PSJ4T1g2SS3YN4BQkAAMBggwQAAGCwQQIAADDYIAEAABiJZEXV9lJui1rqjVqOLKQiZFtQsEVbsYbQVq2tIdYPkqGkDQAAkAI2SAAAAAYbJAAAAIMNEgAAgJF0knacqUnXqmx9zDHHhI4POOAAd863v/1tl919990uW716dSqXCAAAChSvIAEAABhskAAAAAw2SAAAAAYbJAAAAKMgStpqgvW0adNcdvHFF7tMlbKjGDlypMtOPPFElyWbRP7/2X9D1K8D/kO9CcFqL1PcASDbeAUJAADAYIMEAABgsEECAAAwEsm6MHH5FOTjjjvOZW+99VZWH7OpqcllpaWlLmvPnY84fBK76qd16tQp0nnqZ6zY71dbWxvpe7WlZ6YGoVZVVYWOO3To4M5Zt26dy+K8RuOwhtpCrSvVFVPnWY2NjRm5pmKmnsfm5uakT26c10+hKcYubbJ7EK8gAQAAGGyQAAAADDZIAAAABhskAAAAI3aDIlXxtH///jm/jgULFrgsatk1SiGzGMptuaaKy926dXPZuHHjIn3tqFGjXDZkyBCXnXrqqaHj7du3u3Ouv/56ly1evNhlq1evdplaL0OHDnXZoEGDQsfvv/++OyfOhexiVFFR4bKTTz7ZZbfffnvouLy83J0zfPhwl3311VdpX5t6s0LPnj1Dx127dnXnfPzxx2k/JlKjfvez/bdB3Qv79evnsscee8xl7733Xuj4mmuuydyFxRCvIAEAABhskAAAAAw2SAAAAAYbJAAAACN2k7TVtOrRo0e7bOHChS5Ld1ptSUlJxKvz1GOqwtuXX34ZOm5oaEj7MeMi21OQbWH/3nvvdefYAnUQBEHfvn1dpiZdq4KqmoIchSpHP/vssy4755xzXKZKk48//rjL5s6dGzqeNWuWO6fQyv9xnaSt1oEqVquivHpTSZR7U11dncvU2lBZJtXU1LjsiCOOcNn69euzeh1KoUzSVr/7qrzfo0ePHFxN9lRWVrpsy5YtebiS9DFJGwAAIAVskAAAAAw2SAAAAAYbJAAAACN2JW1VwlPTkjds2OAyNYX7r3/9a+j4hz/8oTtHlSOjXpuapHvnnXe6bMqUKaHjvXv3RnrMOMt2wbasrCx0/PTTT7tzxo4d6zJVvlYyWXZV6/Giiy5y2auvvuqywYMHu6y6utplu3btCh2rgqR6E0KcxbWkrdbGgAEDXLZixQqX2XUblX0jRxAEQe/evV2W7hsJolJvOFi6dKnLxo8f77IvvvgiG5f0X+rf3tTUlNeSdq9evVxWaEXldM2YMcNlU6dOdVnUv7H5QEkbAAAgBWyQAAAADDZIAAAABhskAAAAI7sjWTNElaNVofG1115z2RVXXBE6VgXEqNSE7H/+858uU8XKBx54oNWvK7QpyNlmi+wPP/ywO2fgwIEuO+SQQ1yWyUK2WkPqOlRhWl3Hm2++6TL1hoPu3buHjjt16hTpMZE6dc9RE9rVFH61Pmy2c+dOd84JJ5zgsvnz50e6jkxSa0iVtNU9ONvyfY9Un/SgpqkXGvVJA+oeZJ133nkuU29muOCCC1wW5+L2f/AKEgAAgMEGCQAAwGCDBAAAYLBBAgAAMGJX0lbF08mTJ7tMFaFPP/30jF2HKqjNnTvXZWrKtyovbtu2LXSc77JhIbDF1o0bN7pz3njjDZep51ZNPFdrKErpdtKkSe6choYGlymqDLlkyRKXjRs3zmW2PFtfXx/pMZE6VYS+/fbbXaYmO6v1t3jx4tDxr3/9a3fOjh07XPbUU0+57LrrrnNZutQashPbgyAIPvnkE5e15Q0v6cr3fVO9ycLe24MgCA466KAcXE3r1PN1zz33uKy2ttZlN910k8vsmxc+//xzd84HH3zgskL95AheQQIAADDYIAEAABhskAAAAAw2SAAAAEYiWektkUjkvBF37LHHuuzPf/6zy9S0TlUa/N3vfhc6ViVcVe7esGGDy37/+9+7bN68eS5ThTRbsFVlXZXFWUtLix83bGRyDamf3f777x/pPFW6VeXK7du3u8yWZ3Pxc1Klcvu7unXr1lbPibtcr6GozjzzTJfdf//9LqusrHSZKuyfe+65oeNVq1a5c9SUZrW+zz//fJdNnTrVZVu2bHGZLRmr++jEiRNd9tBDD7mspqbGZfnQ2hrK9vqxE+6DIAgWLVrksh49erhM/Xw7d+7sMvtzU7/7Y8aMcdmaNWtcpv5ODhs2zGXvvvuuy3bv3h06VutHFb7jfF9Ktn54BQkAAMBggwQAAGCwQQIAADBiNyhS/bdV9enS6r+jqiFedqia+pRuZf369S6bPXt2pOtQ1EA5pEZ1O1SPSFHnqS6R+m/l+RiIp/ojyB3Vo1C9RNXDUfeYSy+9NHQ8fPhwd06vXr1c9tlnn7lMdU1Ud06x91I11PbRRx91WVz6RnGkBnyqYYzq56Y6PIceeqjL7CffL1++3J2j/nZ27drVZU888YTLTj75ZJepLqcdoLxnzx53TjHhrzYAAIDBBgkAAMBggwQAAGCwQQIAADBiV9JWRci77rrLZTfccIPLBg0a5LJ0y9Gffvqpy9pS1rXXkenBWVE/VTzOA7vSEfXfU6ifJo38OPDAA1328ssvu0y9cUOVYO0w2qj3pf79+7tMlYKjssMo1aDC8vJyl23evNllxXYvSZd6HhYuXOiyww8/3GXdunWL9Bj2/qWGTv70pz912eTJk12mhptGFfXNAMWCV5AAAAAMNkgAAAAGGyQAAACDDRIAAIARu5L2zp07Xfbwww+7rL6+3mUzZsxwWc+ePdO6jgkTJrhsypQpLlPl35NOOsllp5xySuj41ltvdee05VPi8zHtuRjZSbFBEAQjR44MHaup3Ko0uWzZMpfxcyoMs2bNcpktOAeB/nm+8sorLlP3Dkv9/r/00ksui1qOVmVrO61bvRlFvVEGqVm3bp3L5s6d67K+ffu6rE+fPi57/fXXQ8evvvqqO6dfv34uW7VqlcsqKipcpqxcudJlY8eOjfS1xYJXkAAAAAw2SAAAAAYbJAAAAIMNEgAAgJFIVvhLJBKxGJWaSCRcpgqTd9xxh8uuvfbatB5TlS/37NkT6TpUtmvXrtBx1AmqUannSE3rbUsR3GppafEPasR5Dam137t3b5d9/vnnoeOSkpJI31+pq6tzmSqGd+zo3z9h38BgC7dBkNmfby4U0hqKSv3eHXTQQaHj2tpad86WLVtcpu5D6vsPGDDAZc8//7zLbFl88eLF7pxC09oaysf6ifo3S91LOnXq5LKamprQcdSivlor6jHVm57SFfVeGJdJ7MnWD68gAQAAGGyQAAAADDZIAAAABhskAAAAI3YlbVXwilpA7tq1q8vsVNiysjJ3jnoOohbNop5nS5ldunSJ9HVRqUnOqninyqHpKqSCbdSS9tFHH+2yd955p9XvlQv2etUaUiXwOCukNRQX5557rssefPBBl6ky7h//+MfQ8dVXX525C8uTXJa0o95Hon5tVHEpNFuVlZUuO+OMM1w2Z84cl23dujUr15QqStoAAAApYIMEAABgsEECAAAw2CABAAAYflxvDEUttzU2NrrsvvvuCx0feuih7hw75ToIgmDcuHEu69y5c6TrULJdnt29e7fL1PPRHlRUVLisZ8+eLlu3bp3L+vTp47K9e/eGjtVE3FwUt+1jHHPMMe6cN954w2WFNl0byT322GMuU29aUZP/1ddG0ZZyMv5XMT5fP/rRj1w2ePBglz355JO5uJyM4xUkAAAAgw0SAACAwQYJAADAYIMEAABg5HWSdtSp2R06dHCZKp6qf4v92qhTs4cOHeqy9957z2WdOnWK9P22bNkSOq6qqnLnNDc3u0xdrypkqvOyXQqM6xTkAw880GVqvdifSRDoSevHHXdc6Pjuu+9254wYMcJlmS5u2/Vx5plnunP+/ve/u8yWzOMkrmsoznbs2OEy9SkCU6ZMcdnMmTNDx2ptdOzo37ujJvWr3598vCEgl5O020Ldt9U9v5Cov39q/ag3EcUFk7QBAABSwAYJAADAYIMEAABg5KyDFLVvFLUjlO3OjfrvxR988IHLhg0b5jL132Dtf2v+8Y9/7M559913XVZdXe2ynTt3uiwf4tofUc+/ylT/Isr66969uzvn4Ycfdtlpp53msqjDRtV1NDQ0tPqYU6dOdVlNTU2k758PhbSGovYes+0b3/iGy3r37u2yl19+2WV2/d1zzz2tnhMEQbBmzRqX/eIXv3BZe+wgqb9P3bp1i/S1qk+G3KKDBAAAkAI2SAAAAAYbJAAAAIMNEgAAgOGbiFnSllJ11JK2Klbbr1UlQjWIUn36+6GHHhrpaxV7bTfffLM7Z/LkyS6L84CtuGpsbIx0nlovKrND8i655BJ3zoknnuiy0tLSSNehqDVvv58a0rZt2zaXxaWQXUi6dOnisvr6epep+0nU9ReFWgfqzRxR75H2jQkbN25056ji8H333eeyfBSy40g9z2oNqN/XqEOQkR+8ggQAAGCwQQIAADDYIAEAABhskAAAAIycTdLOBTX99uCDDw4dq1Lc3LlzXaZKmupT4tN1+eWXu+yhhx5yWZw/7TmuU5CjUsVWVaR86aWXQsdjx45150Qt67fFrl27Qsfl5eXunEIrZMdhDali/vPPP++ywYMHu2zt2rUuu+yyy1z25Zdfho4z/QaVqEpKSkLHXbt2deeoon+c5XuStlo/Y8aMcdn111/vMlWS37x5c6vnLVy40J2zbNkyl8X570dcMEkbAAAgBWyQAAAADDZIAAAABhskAAAAI2eTtHNBlbRtWe6www5z5/Tv399ly5cvd9ndd9/tMlWMW7RokcsaGhpCx3aibdypsmihU+ulX79+LrNFfzXptra21mVRJ2mr0m1dXZ3LJk2a1OrXIXVqbVdWVrrskEMOcdnAgQNdtmDBApdVV1eHjhcvXuzOqaqqctktt9zispqaGpdFZe9DhVbIjuN9SBWhlyxZ4rKf/exnLps+fbrLTjvtNJf17du31cdUJfCnn37aZZs2bXIZNF5BAgAAMNggAQAAGGyQAAAADDZIAAAARlFN0lZsqU+VL1evXu2ykSNHuuyzzz7L3IUVgThMQY5KlTuPP/54l91www0umz17duh43rx57hxVfIw6xVZN4lVfW4yl7DisITU9/ZNPPnFZnz59XGZLz0Hgp1UHQfqT1tWk7kGDBqX1vQqNepODeh737NmT10naUanf8xtvvNFlP//5z11WVlaWsetQ95Go5Xe73tU9dOnSpS5rbGyMdnF5wCRtAACAFLBBAgAAMNggAQAAGGyQAAAAjKKapK3YQtrmzZvdOap8WV9fn7VrQu6pYuLbb7/tsvPOO89lakp2JqnJ3MgdVSCdM2eOy8aPH++yXbt2uUyVvu20flWKVWv00UcfdVl7oQrwcS77tibqxG31785kSbst08jtpw+oT4SI+uaUQsArSAAAAAYbJAAAAIMNEgAAgMEGCQAAwCj6SdrInjhMQUZhi+saUtOwu3fv7jI1mV9lM2fODB2roqwqgS9fvjzpdbY36nlrbm4uiEnaUQ0ZMsRl1dXVoWM1lXvjxo0u69atm8ts0ToI9ITybdu2ueyRRx4JHd98883unEKb+M8kbQAAgBSwQQIAADDYIAEAABh0kJC2uPZH2ouowwbjrL2sIdsZUT+nQvvZ5UN76CB17tzZZdOmTQsdqwGTf/nLX1ym1pQa5FhaWuqyurq6Vr9fMaxZOkgAAAApYIMEAABgsEECAAAw2CABAAAYlLSRtvZSsEX2sIbQVq2toTivHzW0MUqxuhjK0XFBSRsAACAFbJAAAAAMNkgAAAAGGyQAAADDN8SQkmKYZhyF+ncCqWANoa3Up9jnklrD+5juHek85FaqPwNeQQIAADDYIAEAABhskAAAAAw2SAAAAEbSSdoAAADtEa8gAQAAGGyQAAAADDZIAAAABhskAAAAgw0SAACAwQYJAADA+B9GBc/Metl3XAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 5 is 9.516998291015625 sec\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "print(\"Starting\")\n",
    "history = train(train_ds, EPOCHS)\n",
    "print(\"Finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}